pip install celery

Для работы c Celery из приложения необходим посредник.
Celery может работать с различными брокерами, например с хранилищами
вида «ключ – значение», такими как Redis, или системами обмена сообщения-
ми между приложениями, такими как RabbitMQ. Мы будем работать с послед-
ним, т. к. RabbitMQ является рекомендуемым брокером для Celery.

sudo apt-get install rabbitmq

После установки запустите RabbitMQ, выполнив команду:
rabbitmq-server

Вы увидите вывод, который содержит такую строку:
Starting broker... completed with 10 plugins.
RabbitMQ запущен и готов принимать сообщения.

+++++++++++++++++++++++++++++++++
Подключение Celery к Django-проекту
Нам нужно описать конфигурацию для экземпляра Celery. Создайте новый
файл, celery.py, и расположите его рядом с файлом settings.py. Здесь мы на-
строим наш проект на взаимодействие с Celery. Добавьте в новый файл такой
фрагмент:

import os
from celery import Celery

# Задаем переменную окружения, содержащую название файла настроек нашего проекта.
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myshop.settings')
app = Celery('myshop')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()

В этом коде мы выполняем следующие действия:
1)	задаем переменную окружения DJANGO_SETTINGS_MODULE для консольных
команд Celery;
2) создаем экземпляр приложения с помощью записи app = Celery('myshop');
3)	загружаем конфигурацию из настроек нашего проекта, вызывая метод
config_from_object(). Параметр namespace определяет префикс, который
мы будем добавлять для всех настроек, связанных с Celery. Таким об-
разом, в файле settings.py можно будет задавать конфигурацию Celery
через настройки вида CELERY_, например CELERY_BROKER_URL;
4)	наконец, вызываем процесс поиска и загрузки асинхронных задач по
нашему проекту. Celery пройдет по всем приложениям, указанным в на-
стройке INSTALLED_APPS, и попытается найти файл tasks.py, чтобы загру-
зить код задач.

Вам необходимо импортировать модуль celery.py в файле __init__.py про-
екта, чтобы он выполнялся при старте проекта. Отредактируйте файл myshop/__
init__.py и добавьте в него такой фрагмент:

# Подключение Celery.
from .celery import app as celery_app

Теперь мы можем приступить к созданию асинхронных задач для нашего
проекта.

Настройка CELERY_ALWAYS_EAGER позволит вам выполнять асинхронные задачи локально
в синхронном режиме вместо отправки их в очередь. Это бывает полезно для запуска
юнит-тестов или запуска приложения локально без установки Celery.
Добавление асинхронных задач
Мы добавим асинхронную задачу, которая будет отправлять уведомления на
электронную почту пользователей после создания заказа. Существует догово-
ренность, что асинхронные задачи должны быть расположены в файле
tasks.py в папке приложения.

Добавление асинхронных задач
Мы добавим асинхронную задачу, которая будет отправлять уведомления на
электронную почту пользователей после создания заказа. Существует догово-
ренность, что асинхронные задачи должны быть расположены в файле tasks.
py в папке приложения.

Создайте новый файл tasks.py в каталоге приложения orders. Здесь Celery будет
искать асинхронные задачи при запуске проекта. Добавьте в файл следующий фрагмент:

from celery import task
from django.core.mail import send_mail
from .models import Order
@task
def order_created(order_id):
    """Задача отправки email-уведомлений при успешном оформлении заказа."""
    order = Order.objects.get(id=order_id)
    subject = 'Order nr. {}'.format(order.id)
    message = 'Dear {},\n\nYou have successfully placed an order. Your order id is {}.'.format(order.first_name,
    order.id)
    mail_sent = send_mail(subject, message, 'admin@myshop.com', [order.email])
    return mail_sent

Как можно заметить, задача – это обычная Python-функция с декоратором
task. Мы определили задачу order_created, которая получает один параметр,
order_id. Рекомендуем передавать в качестве аргументов функции только
идентификаторы и получать сами объекты из базы данных лишь во время вы-
полнения задачи. Мы обращаемся к функции Django send_mail(), чтобы отпра-
вить покупателю сообщение на электронную почту.
Вы уже узнали, как настроить Django на работы с SMTP-сервером, в главе 2. Если вы
хотите отладить работу асинхронной задачи без использования SMTP-сервера,
добавьте настройку EMAIL_BACKEND в файл settings.py проекта, как показано ниже:
EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'
Используйте асинхронные задачи не только для трудоемких процессов, но и в случаях,
когда выполняются процессы, которые могут прерваться и потребовать повторных дей-
ствий со стороны пользователя.
Теперь нужно добавить вызов асинхронной задачи в обработчик order_create.
Откройте файл views.py приложения orders, импортируйте функцию order_created
и вызовите ее после очистки корзины при создании заказа:

from .tasks import order_created
def order_create(request):
# ...
if request.method == 'POST':
# ...
if form.is_valid():
# ...
cart.clear()
# Запуск асинхронной задачи.
order_created.delay(order.id)
# ...

++++++++++++++++++++++++++++++++++++++++
Мы используем метод delay(), чтобы запустить задачу асинхронно. Она бу-
дет добавлена в очередь Celery, и ее выполнит первый освободившийся поток.
Откройте другую консоль и запустите процесс Celery из папки проекта с по-
мощью такой команды:
celery -A myshop worker -l info
Рабочий процесс запущен и готов выполнять задачи. Убедитесь, что сервер
Django тоже запущен. Откройте в браузере http://127.0.0.1:8000/ и добавьте не-
сколько товаров в корзину, а затем оформите заказ. В консоли, где вы запусти-
ли рабочий процесс Celery, должен будет появиться такой вывод:
[2017-12-17 17:43:11,462: INFO/MainProcess] Received task:
orders.tasks.order_created[e990ddae-2e30-4e36-b0e4-78bbd4f2738e]
[2017-12-17 17:43:11,685: INFO/ForkPoolWorker-4] Task
orders.tasks.order_created[e990ddae-2e30-4e36-b0e4-78bbd4f2738e] succeeded
in 0.22019841300789267s: 1
Процесс выполнил задачу, и вы должны были получить электронное сооб-
щение о совершении покупки.
Мониторинг Celery
Иногда разработчику необходимо отслеживать выполнение задач. Для этих це-
лей отлично подходит инструмент Flower. Установите его командой:
pip install flower==0.9.2
После установки для запуска Flower выполните из папки проекта команду:
celery -A myshop flower
Откройте в браузере

http://localhost:5555/dashboard.
Вы увидите активные
рабочие процессы Celery и статистику по ним:

Полную документацию по инструменту мониторинга Flower можно найти
на странице https://flower.readthedocs.io/